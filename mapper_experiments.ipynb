{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from source.read_HAR_dataset import read_har_dataset, har_dimensions, har_activities, har_activities_map, har_ind_IDS\n",
    "from source.utils import  filter_dimensions\n",
    "from source.tserie import TSerie\n",
    "from source.utils import classify_dataset\n",
    "from itertools import chain, combinations\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "from source.utils import idsStd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import umap\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from source.augmentation import  * \n",
    "# from cuml.datasets import make_blobs\n",
    "from cuml.neighbors import NearestNeighbors\n",
    "from cuml.manifold import UMAP\n",
    "from cuml.cluster import DBSCAN\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sys.path.insert(0, '/home/texs/Documentos/Repositories/mts_viz')\n",
    "from server.source.storage import MTSStorage\n",
    "\n",
    "def powerset(iterable):\n",
    "    \"powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)\"\n",
    "    s = list(iterable)  # allows duplicate elements\n",
    "    return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))\n",
    "\n",
    "# Z_SCORE_NORM = True\n",
    "EXPERIMENTS_DIR = 'distance_experiments'\n",
    "NORM = 0 # 0: No normalization, 1: centering 2: z_score_norm\n",
    "DATASET = 'HAR-UML20'\n",
    "KFOLDS = 9\n",
    "N_TESTS = 2\n",
    "# METRIC  = 'braycurtis'\n",
    "METRIC  = 'cosine'\n",
    "RESULTS_PATH = 'outputs/augmentation/'\n",
    "AUGMENTATIONS = ['rotation', 'permutation', 'time_warp', 'magnitude_warp', 'scaling', 'jitter']\n",
    "# AUGMENTATIONS = ['none']\n",
    "# AUGMENTATIONS = ['scaling']\n",
    "# ALL_AUGMENTATIONS = ['none', 'rotation', 'permutation', 'time_warp', 'magnitude_warp', 'scaling', 'jitter']\n",
    "# ALL_AUGMENTATIONS = ['none', 'rotation', 'rotation', 'rotation', 'rotation', 'rotation', 'rotation']\n",
    "# ALL_AUGMENTATIONS = ['none'] * 7\n",
    "# AUGMENTATIONS = ['magnitude_warp']\n",
    "REPEATS_PER_AUGMENTATION = 1\n",
    "INCLUDE_ORIGINAL = True\n",
    "# N_DIMS_NAMES = ['Acc', 'Gyro', 'Mag']\n",
    "N_DIMS_NAMES = ['Acc', 'Gyro']\n",
    "# N_DIMS_NAMES = ['Acc']\n",
    "N_DIMENSIONS = [\n",
    "    [\n",
    "        'Accelerometer-X',\t\n",
    "        'Accelerometer-Y',\t\n",
    "        'Accelerometer-Z',\n",
    "    ],\n",
    "    [\n",
    "        'Gyrometer-X',\n",
    "        'Gyrometer-Y',\n",
    "        'Gyrometer-Z',\n",
    "    ],\n",
    "    # [\n",
    "    #     'Magnetometer-X',\n",
    "    #     'Magnetometer-Y',\n",
    "    #     'Magnetometer-Z'\n",
    "    # ]\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self, n_components, n_neighbors):\n",
    "        self.reducer = UMAP(n_components=n_components, n_neighbors=n_neighbors, n_epochs=2000)\n",
    "        self.nearNeigh = NearestNeighbors(n_neighbors=n_neighbors, metric=METRIC)\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        self.nearNeigh.fit(X)\n",
    "        knn_graph = self.nearNeigh.kneighbors_graph(X, mode=\"distance\")\n",
    "        embeddings =  self.reducer.fit_transform(X, y=y, knn_graph=knn_graph.tocsr(), convert_dtype=True)\n",
    "        return embeddings\n",
    "    \n",
    "    def transform(self, X):\n",
    "        knn_graph = self.nearNeigh.kneighbors_graph(X, mode=\"distance\")\n",
    "        embeddings =  self.reducer.transform(X, knn_graph=knn_graph.tocsr(), convert_dtype=True)\n",
    "        return embeddings\n",
    "\n",
    "def augmentData(X, y, I, augmentation, repeat = 3):\n",
    "    X_out = []\n",
    "    y_out = []\n",
    "    I_out = []\n",
    "    for i in range(repeat):\n",
    "        if augmentation == 'rotation':\n",
    "            augmented = rotation(X, angle_range=[-np.pi/4, np.pi/4])\n",
    "            # augmented = rotation(X, angle_range=[-np.pi/64, np.pi/64])\n",
    "        elif augmentation == 'permutation':\n",
    "            augmented = permutation(X)\n",
    "        elif augmentation == 'time_warp':\n",
    "            augmented = time_warp(X, sigma=0.03)\n",
    "        elif augmentation == 'magnitude_warp':\n",
    "            augmented = magnitude_warp(X, sigma=0.015, knot=4)\n",
    "        elif augmentation == 'scaling':\n",
    "            augmented = scaling(X, sigma=0.05)\n",
    "        elif augmentation == 'jitter':\n",
    "            augmented = jitter(X, sigma=0.005)\n",
    "        # elif augmentation == 'magnitude_pert':\n",
    "        #     augmented = magnitude_pert(X, prange=[0, 1])\n",
    "        else:\n",
    "            augmented = X\n",
    "        if len(X_out) == 0:\n",
    "            X_out = augmented\n",
    "            y_out = y\n",
    "            I_out = I\n",
    "        else:\n",
    "            X_out = np.concatenate((X_out, augmented), axis=0)\n",
    "            y_out = np.concatenate((y_out, y), axis=0)\n",
    "            I_out = np.concatenate((I_out, I), axis=0)\n",
    "    return X_out, y_out, I_out\n",
    "\n",
    "def augment(X, y, I, augmentations, repeats_per_augmentation=1, include_original=False):\n",
    "    X_aug = []\n",
    "    y_aug = []\n",
    "    I_aug = []\n",
    "    if include_original:\n",
    "        X_aug = X\n",
    "        y_aug = y\n",
    "        I_aug = I\n",
    "    for augmentation in augmentations:\n",
    "        curr_X_aug, curr_y_aug, curr_I_aug = augmentData(X, y, I, augmentation, repeat=repeats_per_augmentation)\n",
    "        if len(X_aug) == 0:\n",
    "            X_aug = curr_X_aug\n",
    "            y_aug = curr_y_aug\n",
    "            I_aug = curr_I_aug\n",
    "        else:\n",
    "            X_aug = np.concatenate((X_aug, curr_X_aug), axis=0)\n",
    "            y_aug = np.concatenate((y_aug, curr_y_aug), axis=0)\n",
    "            I_aug = np.concatenate((I_aug, curr_I_aug), axis=0)\n",
    "    return X_aug, y_aug, I_aug\n",
    "\n",
    "def minoritySampling(X, y):\n",
    "    rus = RandomUnderSampler(sampling_strategy='not minority', random_state=1)\n",
    "    N, T, D = X.shape\n",
    "    X_temp = X.reshape([N, T * D])\n",
    "    X_temp, y = rus.fit_resample(X_temp, y)\n",
    "    X = X_temp.reshape([X_temp.shape[0], T, D])\n",
    "    return X, y\n",
    "\n",
    "\n",
    "activities_map = {\n",
    "    0: \"Sedentary\",\n",
    "    1: \"Walking\",\n",
    "    2: \"Running\",\n",
    "    3: \"Downstairs\",\n",
    "    4: \"Upstairs\"\n",
    "}\n",
    "def load_data(k):\n",
    "    all_ids = har_ind_IDS\n",
    "    test_ids = all_ids[k: k + N_TESTS]\n",
    "    train_ids = all_ids[:k] + all_ids[k + N_TESTS:]        \n",
    "    \n",
    "    data = read_har_dataset('./datasets/HAR-UML20/', train_ids=train_ids, test_ids=test_ids, val_ids=[], cache=True)\n",
    "    ids_train, X_train, y_train, I_train, train_kcal_MET = data['train']\n",
    "    # ids_val, X_val, y_val, I_val, val_kcal_MET = data['val']\n",
    "    ids_test, X_test, y_test, I_test, test_kcal_MET = data['test']\n",
    "    \n",
    "    \n",
    "\n",
    "    all_dimensions = har_dimensions\n",
    "    activities_map = har_activities_map\n",
    "    \n",
    "    y_train[y_train==0] = 0\n",
    "    y_train[y_train==1] = 0\n",
    "    y_train[y_train==2] = 0\n",
    "    y_test[y_test==0] = 0\n",
    "    y_test[y_test==1] = 0\n",
    "    y_test[y_test==2] = 0\n",
    "\n",
    "    for i in range(3, len(har_activities)):\n",
    "        y_train[y_train==i] = i - 2\n",
    "        y_test[y_test==i] = i - 2\n",
    "    \n",
    "    ind_std_train = idsStd(train_ids , X_train, I_train)\n",
    "    ind_std_test = idsStd(test_ids, X_test, I_test)\n",
    "    \n",
    "    unique, counts = np.unique(y_train, return_counts=True)\n",
    "    unique, counts = np.unique(y_test, return_counts=True)\n",
    "    \n",
    "    I_train = np.expand_dims(I_train, axis=1)\n",
    "    I_test = np.expand_dims(I_test, axis=1)\n",
    "    ltrain = np.arange(len(y_train))\n",
    "    ltest = np.arange(len(y_test))\n",
    "    \n",
    "    X_train, zlabels_train = minoritySampling(X_train, ltrain)\n",
    "    X_test, zlabels_test = minoritySampling(X_test, ltest)\n",
    "    \n",
    "    y_train = y_train[ltrain]\n",
    "    I_train = I_train[ltrain]\n",
    "    y_test = y_test[ltest]\n",
    "    I_test = I_test[ltest]\n",
    "    \n",
    "    return X_train, y_train, I_train, X_test, y_test, I_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDS: [2, 3, 4, 5, 6, 7, 8, 9]\n",
      "Test IDS: [0, 1]\n",
      "Val IDS: []\n",
      "Loading dataset from cache...\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, I_train, X_test, y_test, I_test = load_data(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [\n",
    "    'Accelerometer-X',\t\n",
    "    'Accelerometer-Y',\t\n",
    "    'Accelerometer-Z',\n",
    "    'Gyrometer-X',\n",
    "    'Gyrometer-Y',\n",
    "    'Gyrometer-Z'\n",
    "]\n",
    "\n",
    "X_train = filter_dimensions(X_train, har_dimensions, dimensions)\n",
    "X_test = filter_dimensions(X_test, har_dimensions, dimensions)\n",
    "\n",
    "mts_train = TSerie(X = X_train, y = y_train, I = I_train, dimensions = dimensions, classLabels=har_activities_map)\n",
    "mts_test = TSerie(X = X_test, y = y_test, I = I_test, dimensions = dimensions, classLabels=har_activities_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/texs/Documentos/Repositories/mts_feature_learning/source/augmentation.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  warp = np.concatenate(np.random.permutation(splits)).ravel()\n",
      "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "mts shape: N: 6300 -  T: 200 - D: 6\n",
      "[0.14445157998423733, 0.010102773155986244, 0.009583925562968084, 0.005803086356904881, 0.019979127808439388, 0.0036343999195383907]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "storage = MTSStorage('har_augmentations')\n",
    "\n",
    "# storage.delete()\n",
    "storage.load()\n",
    "\n",
    "mode = 1 # 0: original - 1: minMax - 2: Centered - 3: Zscore\n",
    "\n",
    "cum_list =[]\n",
    "for augmentation in AUGMENTATIONS:\n",
    "        mts_train.X = mts_train.X_o\n",
    "        \n",
    "        if mode == 1 or mode == 2 or mode == 3:\n",
    "                minl, maxl = mts_train.minMaxNormalization()\n",
    "        \n",
    "        train_aug, y_aug, I_aug = augment(\n",
    "                mts_train.X, mts_train.y, mts_train.I,\n",
    "                repeats_per_augmentation = 1,\n",
    "                # augmentations = ['rotation', 'permutation', 'time_warp', 'magnitude_warp', 'scaling', 'jitter'],\n",
    "                augmentations = [augmentation],\n",
    "                include_original = False\n",
    "        )\n",
    "        mts_aug = TSerie(X = train_aug, y = y_aug, I = I_aug, dimensions = dimensions, classLabels=har_activities_map)\n",
    "        \n",
    "        if mode == 2:\n",
    "                mts_train.center()\n",
    "                mts_aug.center()\n",
    "        elif mode == 3:\n",
    "                mts_train.znorm()\n",
    "                mts_aug.znorm()\n",
    "\n",
    "        mts_train.folding_features_v1()\n",
    "        mts_aug.folding_features_v1()\n",
    "\n",
    "        reducer = FeatureExtractor(2, 15)\n",
    "        train_coords = reducer.fit_transform(mts_train.features, mts_train.y)\n",
    "        aug_coords = reducer.transform(mts_aug.features)\n",
    "\n",
    "       \n",
    "\n",
    "        storage.add_mts(\n",
    "                'original_{}_{}'.format(augmentation, mode),\n",
    "                mts_train.X, \n",
    "                dimensions,\n",
    "                coords={\n",
    "                        'umap': train_coords\n",
    "                }, \n",
    "                labels={\n",
    "                        'activities': mts_train.y, \n",
    "                }, \n",
    "                labelsNames={'activities': activities_map },\n",
    "                sampling = True,\n",
    "                n_samples = 400\n",
    "        )\n",
    "\n",
    "        storage.add_mts(\n",
    "                'augmented_{}_{}'.format(augmentation, mode),\n",
    "                mts_aug.X, \n",
    "                dimensions,\n",
    "                coords={\n",
    "                        'umap': aug_coords\n",
    "                }, \n",
    "                labels={\n",
    "                        'activities': mts_aug.y, \n",
    "                }, \n",
    "                labelsNames={'activities': activities_map },\n",
    "                sampling = True,\n",
    "                n_samples = 400\n",
    "        )\n",
    "\n",
    "        storage.save()\n",
    "\n",
    "\n",
    "        n1 = 0\n",
    "        n2 = 10\n",
    "        acum_dist = 0\n",
    "        for i in range(mts_train.N):\n",
    "                acum_dist = acum_dist + distance.braycurtis(mts_train.features[i], mts_aug.features[i])\n",
    "        acum_dist = acum_dist / mts_train.N\n",
    "\n",
    "        cum_list.append(acum_dist)\n",
    "\n",
    "        # print('Mean distance {}'.format(acum_dist))\n",
    "        \n",
    "        serie1_o = mts_train.features[n1]\n",
    "        serie1_a = mts_aug.features[n1]\n",
    "        serie2_o = mts_train.features[n2]\n",
    "        serie2_a = mts_aug.features[n2]\n",
    "\n",
    "        plt.plot(serie1_a)\n",
    "        plt.plot(serie1_o)\n",
    "        \n",
    "        spath = os.path.join(EXPERIMENTS_DIR, '{}_serie_{}.png'.format(mode, augmentation))\n",
    "        plt.savefig(spath)\n",
    "        plt.clf()\n",
    "\n",
    "\n",
    "print(cum_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- rotation: 0.1445\n",
      "- permutation: 0.0101\n",
      "- time_warp: 0.0096\n",
      "- magnitude_warp: 0.0058\n",
      "- scaling: 0.02\n",
      "- jitter: 0.0036\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(AUGMENTATIONS)):\n",
    "    print('- {}: {}'.format(AUGMENTATIONS[i], round(cum_list[i], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('rapidsml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f51f79755ef8f79693022c2238daee50231b90d0a3e393b6e63d90a9477d06f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
